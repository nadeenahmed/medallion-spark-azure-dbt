[0m04:26:49.241724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CCF501E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CD25928D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CD25900E0>]}


============================== 04:26:49.270689 | fba59e8e-5b83-4c90-9209-5bbf0ae260eb ==============================
[0m04:26:49.270689 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:26:49.275694 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt init', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:26:49.477574 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse dict {'dir': WindowsPath('C:/Users/NanoChip/.dbt')}
[0m04:26:49.486565 [info ] [MainThread]: Creating dbt configuration folder at 
[0m04:27:16.368432 [debug] [MainThread]: Starter project path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\include\starter_project
[0m04:27:16.562327 [info ] [MainThread]: 
Your new dbt project "medallion_dbt_spark" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m04:27:16.588308 [info ] [MainThread]: Setting up your profile.
[0m04:27:39.244462 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:27:39.251469 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:27:39.262451 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:31:44.533468 [info ] [MainThread]: Profile medallion_dbt_spark written to C:\Users\NanoChip\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m04:31:44.583436 [debug] [MainThread]: Command `dbt init` succeeded at 04:31:44.582428 after 296.07 seconds
[0m04:31:44.596419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CD23705F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CD354F710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029CD2EE4D10>]}
[0m04:31:44.599417 [debug] [MainThread]: Flushing usage events
[0m04:32:19.480951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6ADE51280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6ADDF2570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6AAD81D60>]}


============================== 04:32:19.502941 | af05b2f2-5f3e-4b45-95d2-941c00b0c72d ==============================
[0m04:32:19.502941 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:32:19.506928 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt init', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:33:20.800993 [info ] [MainThread]: A project called medallion_dbt_spark already exists here.
[0m04:33:20.807049 [debug] [MainThread]: Command `dbt init` succeeded at 04:33:20.806050 after 61.92 seconds
[0m04:33:20.809048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6ADBF26F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6AE494C80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6ADE51280>]}
[0m04:33:20.813035 [debug] [MainThread]: Flushing usage events
[0m04:33:34.207624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0CB5F6C30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0CB82CF20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0CB69B9E0>]}


============================== 04:33:34.221612 | 181f9ac5-cb7a-4502-a44c-055d55aa161f ==============================
[0m04:33:34.221612 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:33:34.224594 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt init', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:35:00.211525 [error] [MainThread]: Encountered an error:

[0m04:35:00.229526 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\main.py", line 470, in init
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\task\init.py", line 325, in run
    project_name = self.get_valid_project_name()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\task\init.py", line 279, in get_valid_project_name
    name = click.prompt("Enter a name for your project (letters, digits, underscore)")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\click\termui.py", line 164, in prompt
    value = prompt_func(prompt)
            ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\click\termui.py", line 147, in prompt_func
    raise Abort() from None
click.exceptions.Abort

[0m04:35:00.271485 [debug] [MainThread]: Command `dbt init` failed at 04:35:00.270502 after 86.41 seconds
[0m04:35:00.274480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0C94C5100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0CBA039B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B0CBA60A10>]}
[0m04:35:00.277477 [debug] [MainThread]: Flushing usage events
[0m04:35:19.587321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262BB6AE540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262B8F1C860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262BB5EB230>]}


============================== 04:35:19.602321 | ae814b4d-3d14-42ff-abeb-5d32ab79f65f ==============================
[0m04:35:19.602321 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:35:19.605314 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m04:35:19.699266 [info ] [MainThread]: dbt version: 1.8.6
[0m04:35:19.702258 [info ] [MainThread]: python version: 3.12.0
[0m04:35:19.704268 [info ] [MainThread]: python path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\python.exe
[0m04:35:19.707261 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m04:35:20.154010 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:35:20.156009 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:35:20.157995 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:35:25.685905 [info ] [MainThread]: Using profiles dir at C:\Users\NanoChip\.dbt
[0m04:35:25.689902 [info ] [MainThread]: Using profiles.yml file at C:\Users\NanoChip\.dbt\profiles.yml
[0m04:35:25.691892 [info ] [MainThread]: Using dbt_project.yml file at E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml
[0m04:35:25.694906 [info ] [MainThread]: adapter type: databricks
[0m04:35:25.698898 [info ] [MainThread]: adapter version: 1.8.5
[0m04:35:25.703893 [info ] [MainThread]: Configuration:
[0m04:35:25.708875 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:35:25.712893 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m04:35:25.725865 [info ] [MainThread]: Required dependencies:
[0m04:35:25.736882 [debug] [MainThread]: Executing "git --help"
[0m04:35:25.866785 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:35:25.870790 [debug] [MainThread]: STDERR: "b''"
[0m04:35:25.871780 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:35:25.878782 [info ] [MainThread]: Connection:
[0m04:35:25.881775 [info ] [MainThread]:   host: https://adb-3584644424037889.9.azuredatabricks.net
[0m04:35:25.885792 [info ] [MainThread]:   http_path: sql/protocolv1/o/3584644424037889/0906-234004-meso5b4y
[0m04:35:25.888784 [info ] [MainThread]:   catalog: hive_metastore
[0m04:35:25.892768 [info ] [MainThread]:   schema: saleslt
[0m04:35:25.897766 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m04:35:25.902767 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(13668, 14656), compute-name=) - Creating connection
[0m04:35:25.909783 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m04:35:25.914757 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(13668, 14656), compute-name=) - Acquired connection on thread (13668, 14656), using default compute resource
[0m04:35:25.917754 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=None, name=debug, idle-time=0.001999378204345703s, acquire-count=1, language=None, thread-identifier=(13668, 14656), compute-name=) - Checking idleness
[0m04:35:25.919753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=None, name=debug, idle-time=0.004996776580810547s, acquire-count=1, language=None, thread-identifier=(13668, 14656), compute-name=) - Retrieving connection
[0m04:35:25.921767 [debug] [MainThread]: Using databricks connection "debug"
[0m04:35:25.929759 [debug] [MainThread]: On debug: select 1 as id
[0m04:35:25.936769 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:35:27.689751 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=639b9171-78e1-4b74-9b7e-e6157f7e93fd, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(13668, 14656), compute-name=) - Connection created
[0m04:35:27.700723 [debug] [MainThread]: Databricks adapter: Cursor(session-id=639b9171-78e1-4b74-9b7e-e6157f7e93fd, command-id=Unknown) - Created cursor
[0m04:35:30.111098 [debug] [MainThread]: SQL status: OK in 4.170 seconds
[0m04:35:30.127086 [debug] [MainThread]: Databricks adapter: Cursor(session-id=639b9171-78e1-4b74-9b7e-e6157f7e93fd, command-id=6f930984-3774-4889-a947-18cc53f6a716) - Closing cursor
[0m04:35:30.134022 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623256022672, session-id=639b9171-78e1-4b74-9b7e-e6157f7e93fd, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13668, 14656), compute-name=) - Released connection
[0m04:35:30.140079 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:35:30.150072 [info ] [MainThread]: [31m1 check failed:[0m
[0m04:35:30.160020 [info ] [MainThread]: Project loading failed for the following reason:
 project path <E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml> not found

[0m04:35:30.197987 [debug] [MainThread]: Command `dbt debug` failed at 04:35:30.195989 after 11.24 seconds
[0m04:35:30.208005 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m04:35:30.225996 [debug] [MainThread]: On debug: Close
[0m04:35:30.242975 [debug] [MainThread]: Databricks adapter: Connection(session-id=639b9171-78e1-4b74-9b7e-e6157f7e93fd) - Closing connection
[0m04:35:30.882364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262BB6AE540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C63E4E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C61C5220>]}
[0m04:35:30.890378 [debug] [MainThread]: Flushing usage events
[0m04:36:00.454965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263004E8D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026303526780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026302F22C30>]}


============================== 04:36:00.468938 | 1d0ea44f-89cf-420b-9874-96721c7486fe ==============================
[0m04:36:00.468938 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:36:00.473935 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt init', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:36:08.677681 [debug] [MainThread]: Starter project path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\include\starter_project
[0m04:36:08.733652 [info ] [MainThread]: 
Your new dbt project "medallion_spark_dbt" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m04:36:08.741642 [info ] [MainThread]: Setting up your profile.
[0m04:36:12.073427 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:36:12.075402 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:36:12.078400 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:37:24.624853 [info ] [MainThread]: Profile medallion_spark_dbt written to C:\Users\NanoChip\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m04:37:24.644866 [debug] [MainThread]: Command `dbt init` succeeded at 04:37:24.636872 after 84.51 seconds
[0m04:37:24.655836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026303E8BD70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026303A08440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263043A8E90>]}
[0m04:37:24.659850 [debug] [MainThread]: Flushing usage events
[0m04:37:59.932514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBBAE13650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBBAE113A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBBAE11310>]}


============================== 04:37:59.949496 | 4d283d76-0e3a-499f-b1e5-2ab0adb5b4f1 ==============================
[0m04:37:59.949496 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:37:59.954496 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:38:00.515169 [info ] [MainThread]: dbt version: 1.8.6
[0m04:38:00.522157 [info ] [MainThread]: python version: 3.12.0
[0m04:38:00.528153 [info ] [MainThread]: python path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\python.exe
[0m04:38:00.532166 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m04:38:01.190332 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:38:01.194317 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:38:01.196325 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:38:09.995524 [info ] [MainThread]: Using profiles dir at C:\Users\NanoChip\.dbt
[0m04:38:09.998523 [info ] [MainThread]: Using profiles.yml file at C:\Users\NanoChip\.dbt\profiles.yml
[0m04:38:10.001521 [info ] [MainThread]: Using dbt_project.yml file at E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml
[0m04:38:10.008519 [error] [MainThread]: Encountered an error:
Internal Error
  Profile should not be None if loading profile completed
[0m04:38:10.023522 [debug] [MainThread]: Command `dbt debug` failed at 04:38:10.021512 after 10.62 seconds
[0m04:38:10.036515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBBB47C2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBB563EE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EBC5D9E480>]}
[0m04:38:10.042497 [debug] [MainThread]: Flushing usage events
[0m04:38:27.987153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214165F6420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214185E3140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214185E1340>]}


============================== 04:38:28.003142 | 0f737d81-fc30-4212-b9f3-d6a2d5d7c4bc ==============================
[0m04:38:28.003142 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:38:28.008140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:38:28.136077 [info ] [MainThread]: dbt version: 1.8.6
[0m04:38:28.139076 [info ] [MainThread]: python version: 3.12.0
[0m04:38:28.142069 [info ] [MainThread]: python path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\python.exe
[0m04:38:28.146060 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m04:38:28.745714 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:38:28.748735 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:38:28.751724 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:38:34.890174 [info ] [MainThread]: Using profiles dir at C:\Users\NanoChip\.dbt
[0m04:38:34.895173 [info ] [MainThread]: Using profiles.yml file at C:\Users\NanoChip\.dbt\profiles.yml
[0m04:38:34.899187 [info ] [MainThread]: Using dbt_project.yml file at E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml
[0m04:38:34.908162 [error] [MainThread]: Encountered an error:
Internal Error
  Profile should not be None if loading profile completed
[0m04:38:34.922176 [debug] [MainThread]: Command `dbt debug` failed at 04:38:34.918160 after 7.38 seconds
[0m04:38:34.926152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021419331670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214196B0D70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021424063E90>]}
[0m04:38:34.930166 [debug] [MainThread]: Flushing usage events
[0m04:41:43.210029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001186C65C860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001186E9097F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001186EFCCF20>]}


============================== 04:41:43.228005 | 167677e0-172f-4134-9a39-a6ffe696934a ==============================
[0m04:41:43.228005 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:41:43.237021 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:41:43.398920 [info ] [MainThread]: dbt version: 1.8.6
[0m04:41:43.402911 [info ] [MainThread]: python version: 3.12.0
[0m04:41:43.405905 [info ] [MainThread]: python path: C:\Users\NanoChip\AppData\Local\Programs\Python\Python312\python.exe
[0m04:41:43.407913 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m04:41:44.139491 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m04:41:44.141495 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m04:41:44.142479 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m04:41:52.234944 [info ] [MainThread]: Using profiles dir at C:\Users\NanoChip\.dbt
[0m04:41:52.237919 [info ] [MainThread]: Using profiles.yml file at C:\Users\NanoChip\.dbt\profiles.yml
[0m04:41:52.240919 [info ] [MainThread]: Using dbt_project.yml file at E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml
[0m04:41:52.244933 [info ] [MainThread]: adapter type: databricks
[0m04:41:52.249930 [info ] [MainThread]: adapter version: 1.8.5
[0m04:41:52.252913 [info ] [MainThread]: Configuration:
[0m04:41:52.256914 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:41:52.260906 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m04:41:52.270919 [info ] [MainThread]: Required dependencies:
[0m04:41:52.283908 [debug] [MainThread]: Executing "git --help"
[0m04:41:52.414835 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:41:52.416815 [debug] [MainThread]: STDERR: "b''"
[0m04:41:52.418815 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:41:52.421813 [info ] [MainThread]: Connection:
[0m04:41:52.424836 [info ] [MainThread]:   host: adb-3584644424037889.9.azuredatabricks.net
[0m04:41:52.427815 [info ] [MainThread]:   http_path: sql/protocolv1/o/3584644424037889/0906-234004-meso5b4y
[0m04:41:52.430810 [info ] [MainThread]:   catalog: hive_metastore
[0m04:41:52.433806 [info ] [MainThread]:   schema: saleslt
[0m04:41:52.438810 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m04:41:52.441804 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(12844, 8932), compute-name=) - Creating connection
[0m04:41:52.443813 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m04:41:52.446806 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12844, 8932), compute-name=) - Acquired connection on thread (12844, 8932), using default compute resource
[0m04:41:52.449802 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=None, name=debug, idle-time=0.0020117759704589844s, acquire-count=1, language=None, thread-identifier=(12844, 8932), compute-name=) - Checking idleness
[0m04:41:52.450796 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=None, name=debug, idle-time=0.0039904117584228516s, acquire-count=1, language=None, thread-identifier=(12844, 8932), compute-name=) - Retrieving connection
[0m04:41:52.461791 [debug] [MainThread]: Using databricks connection "debug"
[0m04:41:52.464790 [debug] [MainThread]: On debug: select 1 as id
[0m04:41:52.466787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:41:53.403992 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=fe1a651b-46e1-4876-9e3d-2676d098ca96, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(12844, 8932), compute-name=) - Connection created
[0m04:41:53.418928 [debug] [MainThread]: Databricks adapter: Cursor(session-id=fe1a651b-46e1-4876-9e3d-2676d098ca96, command-id=Unknown) - Created cursor
[0m04:41:53.900186 [debug] [MainThread]: SQL status: OK in 1.430 seconds
[0m04:41:53.943191 [debug] [MainThread]: Databricks adapter: Cursor(session-id=fe1a651b-46e1-4876-9e3d-2676d098ca96, command-id=378f749e-7344-429c-bba6-234dfbe93cd9) - Closing cursor
[0m04:41:53.952159 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1204632489760, session-id=fe1a651b-46e1-4876-9e3d-2676d098ca96, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(12844, 8932), compute-name=) - Released connection
[0m04:41:53.965158 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:41:53.983161 [info ] [MainThread]: [31m1 check failed:[0m
[0m04:41:54.000135 [info ] [MainThread]: Project loading failed for the following reason:
 project path <E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml> not found

[0m04:41:54.081080 [debug] [MainThread]: Command `dbt debug` failed at 04:41:54.079092 after 11.97 seconds
[0m04:41:54.087080 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m04:41:54.106066 [debug] [MainThread]: On debug: Close
[0m04:41:54.118074 [debug] [MainThread]: Databricks adapter: Connection(session-id=fe1a651b-46e1-4876-9e3d-2676d098ca96) - Closing connection
[0m04:41:54.358582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001187980B950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011879B10F20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011879B13E30>]}
[0m04:41:54.360564 [debug] [MainThread]: Flushing usage events
[0m04:58:47.564936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FB7CC800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FD973020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FD972750>]}


============================== 04:58:47.607909 | 8f23c13c-80a4-4bf3-8639-1995a99b7bf1 ==============================
[0m04:58:47.607909 [info ] [MainThread]: Running with dbt=1.8.6
[0m04:58:47.612918 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\NanoChip\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:58:47.616897 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path E:\FCAI\42\Big Data\Medallion-spark-azure-dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m04:58:47.629900 [debug] [MainThread]: Command `dbt snapshot` failed at 04:58:47.628914 after 0.69 seconds
[0m04:58:47.632892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FB7CC800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FE0D3F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000219FDE1D370>]}
[0m04:58:47.638904 [debug] [MainThread]: Flushing usage events
